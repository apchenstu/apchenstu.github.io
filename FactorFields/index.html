<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="A novel approach that achieves photo-realistic rendering, fast reconstruction, and compact modeling.">
    <meta name="author" content="Anpei Chen,
                                Zexiang Xu,
                                Xinyue Wei,
                                Siyu Tang,
                                Hao Su,
                                Andreas Geiger">

    <title>Factor Fields and Beyond</title>

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
        <link rel="icon" href="img/logo.ico" type="image/x-ico">

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</head>

<style>
    .SIGGRAPH-color {
        color: rgb(213, 168, 76);
    }
    .author-color {
         color: rgb(226, 131, 83);
    }
</style>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
        <h1 class="nerf_title_v2">Factor Fields and Beyond</h1>
        <p></p>
        <h3 class="nerf_subheader_v2">Our approach is accepted by <b class="SIGGRAPH-color">SIGGRAPH 2023 (Journal Track)</b> <br>
        TL; DR:</b> Providing a <b>unified formula</b> (Factor Fields) and a <b>dictionary factorization</b> approach (Beyond)
        </h3>
    <!-- <hr> -->
    <p class="authors">
        <a href="https://apchenstu.github.io/" class="author-color"> Anpei Chen</a><sup> 1,4,5</sup>&#160;&#160;
        <a href="http://cseweb.ucsd.edu/~zex014/" class="author-color"> Zexiang Xu</a><sup> 2</sup>&#160;&#160;
        <a href="https://sarahweiii.github.io/" class="author-color"> Xinyue Wei</a><sup> 3</sup>&#160;&#160;
        <a href="https://inf.ethz.ch/people/person-detail.MjYyNzgw.TGlzdC8zMDQsLTg3NDc3NjI0MQ==.html" class="author-color"> Siyu Tang</a><sup> 1</sup>&#160;&#160;
        <a href="https://cseweb.ucsd.edu/~haosu/" class="author-color"> Hao Su</a><sup> 3</sup>&#160;&#160;
        <a href="http://www.cvlibs.net/" class="author-color"> Andreas Geiger</a><sup> 4,5</sup>&#160;&#160;
    </p>

    <p id="institution">
      <sup>1</sup>ETH Z√ºrich&#160;&#160;
      <sup>2</sup>Adobe Research&#160;&#160;
      <sup>3</sup>UC San Diego&#160;&#160;
      <sup>4</sup>University of T√ºbingen&#160;&#160;
      <sup>5</sup>T√ºbingen AI Center&#160;&#160;
    </p>
</div>

<div class="container">
   <div class="row mb-3" id="links">
        <div class="mx-auto">
            <ul class="nav">
                <li class="nav-item text-center">
                    <a href="https://arxiv.org/abs/2302.01226" class="nav-link" >
                        <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                            <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                        </svg><br>
                        FactorFields
                    </a>
                <li class="nav-item text-center">
                    <a href="https://arxiv.org/abs/2302.01226" class="nav-link" >
                        <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                            <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                        </svg><br>
                        Beyond
                    </a>
                <li class="nav-item text-center">
                    <a href="https://github.com/autonomousvision/factor-fields" class="nav-link">
                        <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                            <path fill="currentColor" d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z" />
                        </svg><br>
                        Code
                    </a>
            </ul>
        </div>
    </div>
</div>

<div class="container">
    <div class="w-container">
        <!-- <h2 class="grey-heading_nerf">Overview Video</h2> -->
<!--    <div class="section">-->
        <div class="vcontainer">
            <iframe class='video' src="https://www.youtube.com/embed/3n0tdURqPeM" frameborder="0"
                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
        </div>

    </div>

<!--<hr>-->
    </br></br>
    <div data-anchor="slide1" class="section nerf_section">
        <div class="grey_container w-container">
            <h2 class="grey-heading_nerf">
                Factor Fields
            </h2>
            <p class="paragraph-3 nerf_text">
                Factor Fields decomposes a signal into a product of factors, each represented by a classical or neural field representation which operates on transformed input coordinates. 
                This decomposition results in a unified framework that accommodates several recent signal representations including NeRF, Plenoxels, EG3D, Instant- NGP, and TensoRF. 
            </p>
            <div class="columns-5 w-row">
                <img src="img/framework.png" style="width:100%; margin-right:0px; margin-top:0px;">
            </div>
<!--            <img src="img/teaser_v6.png" alt="" class="nerf_network"/>-->
            <p class="paragraph-3 nerf_text">
                Factor Fields decomposes a signal into <script type="math/tex">N</script> factors <script type="math/tex">\mathbf{f}_1</script> to <script type="math/tex">\mathbf{f}_N</script>, each of which is represented by one out of many different field representations (bottom-left) operating on coordinate transformations <script type="math/tex">\boldsymbol{\gamma}_1</script> to <script type="math/tex">\boldsymbol{\gamma}_N</script>. The resulting product field is passed to a projection function (e.g., MLP) which maps it to the signal‚Äôs output domain.
            </p>


            <p class="paragraph-3 nerf_text">
                The above pipeline can be rewrited as the folling equation:
                <h3 class="nerf_header_v2"><script type="math/tex">{\displaystyle \hat{\mathbf{s}}(\mathbf{x}) = \mathcal{P}\left(\prod_{i=1}^N \mathbf{f}_i\left(\mathbf{\gamma}_i(\mathbf{x})\right)\right)}</script></h3>
            </p>
            <ul style="text-align: left; margin-left: 30px">
              <li>\(\prod\) denotes the element-wise product of a sequence of factors</li>
              <li>each factor \(\mathbf{f}_i:\mathbb{R}^{F_i}\rightarrow\mathbb{R}^K\) is equipped with its own coordinate transformation \(\gamma_i:\mathbb{R}^D\rightarrow\mathbb{R}^{F_i}\)</li>
              <li>projection function \(\mathcal{P}\) maps the K-dimensional Hadamard product \(\prod_{i=1}^N \mathbf{f}_i\left(\mathbf{\gamma}_i(\mathbf{x})\right)\)
     to ùëÑ-dimentional signal \(\mathbf{s}\).

            </ul>

            </p>

            <h2 class="grey-heading_nerf">
                Diectionary Factorization (DiF)
            </h2>
            <p class="paragraph-3 nerf_text">
                Inspired by classical sparse coding and principal component analysis.
                We assume that signals are not random, but <b>structured</b> and hence share similar patterns within the same signal as well as between different signals. 
                DiF decompose a signal into a <b>basis field</b> and a <b>coefficient field</b>. 
                By leveraging periodic coordinate transformations, we can apply the same basis functions across various locations and scales.
            </p>
            <div class="columns-5 w-row">
                <img src="img/DiF.png" style="width:95%; margin-right:0px; margin-top:0px;">
            </div>
            <p class="paragraph-3 nerf_text" style="text-align: center;">
                DiF is an instantiate of Factor Fields with Multi-Scale and Multi-Factor
            </p>
        </div>
    </div>



    </br></br>
    <div class="section">
        <s2>Performance</s2>
        <hr>
        <h2 class="grey-heading_nerf">
            Images
        </h2>
        <p class="paragraph-3 nerf_text">
            <b class="SIGGRAPH-color">Input:</b> All image pixels <br>
            <b class="SIGGRAPH-color">Evaluation:</b> PSNR on the whole image; Training time; Model parameters; 
        </p>
        <div class="columns-5 w-row">
                <img src="img/images.png" style="width:95%; margin-right:0px; margin-top:0px;">
        </div>
        <p class="paragraph-3 nerf_text">
        our method achieves better reconstruction quality on all
        images when using the same model size. While optimization is slower than Instant-NGP, we use a vanilla PyTorch implementation without customized CUDA
        kernels. ‚ÄúSummer Day‚Äù credit goes to Johan Hendrik Weissenbruch and rijksmuseum. ‚ÄúAlbert‚Äù credit goes to Orren Jack Turner. ‚ÄúPluto‚Äù credit goes to NASA.
        ‚ÄúGirl With a Pearl Earring‚Äù renovation ¬©Koorosh Orooj (CC BY-SA 4.0).
        </p>

        <hr>
        <h2 class="grey-heading_nerf">
            SDFs
        </h2>
        <p class="paragraph-3 nerf_text">
            <b class="SIGGRAPH-color">Input:</b> 8M SDF points sampled from the target meshes for training, with 80% points
            near the surface and the remaining 20% points uniformly distributed inside the unit volume<br>
            <b class="SIGGRAPH-color">Evaluation:</b> We randomly sample 16M points for evaluation and calculate
            the geometric IOU metric based on the SDF sign; Training time;
        </p>
        <div class="columns-5 w-row">
                <img src="img/sdfs.png" style="width:95%; margin-right:0px; margin-top:0px;">
        </div>
        <p class="paragraph-3 nerf_text">
        We show qualitative visual comparisons on the top and
        quantitative comparisons on the bottom including the number of parameters, reconstruction time, gIoU, and chamfer distance (CD). DiF-Grid and Instant-NGP
        [MuÃàller et al. 2022] are trained for 10ùëò iterations, while SIREN [Sitzmann et al. 2020] and NeRF with Frequency Position Encoding (PE) [Tancik et al. 2020] are trained for 200ùëò iterations.
        </p>

        <hr>
        <h2 class="grey-heading_nerf">
            NeRF
        </h2>
        <p class="paragraph-3 nerf_text">
            <b class="SIGGRAPH-color">Input:</b> Multi-view images<br>
            <b class="SIGGRAPH-color">Evaluation:</b> PSNR/SSIM on novel views; Training time;
        </p>
        <div class="columns-5 w-row">
                <img src="img/table-nerf.png" style="width:95%; margin-right:0px; margin-top:0px;">
        </div>

<div class="section hero nerf-_v2 wf-section ">
            <div class="container-2 nerf_header_v2 w-container">

                <div data-delay="10000" data-animation="slide" class="nerf_slider_v2 w-slider" data-autoplay="true" data-easing="ease" data-hide-arrows="false" data-disable-swipe="false" data-autoplay-limit="0" data-nav-spacing="3" data-duration="800" data-infinite="true"><div class="mask w-slider-mask">

                  <div class="slide w-slide">
                      <div class="div-block-9 first_video">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/lego.jpg">
                                <source src="video/lego.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/lego.jpg">
                                <source src="video/lego.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>

                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/mic.jpg">
                                <source src="video/mic.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/mic.jpg">
                                  <source src="video/mic.mp4" type="video/mp4">
                                  Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div>

                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/ship.jpg">
                                <source src="video/ship.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/ship.jpg">
                                <source src="video/ship.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  pond -->
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/materials.jpg">
                                <source src="video/materials.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/materials.jpg">
                                <source src="video/materials.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  family -->
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/hotdog.jpg">
                                <source src="video/hotdog.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/hotdog.jpg">
                                <source src="video/hotdog.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  succulent -->
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/ship.jpg">
                                <source src="video/ship.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/ship.jpg">
                                <source src="video/ship.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  ship -->
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/ficus.jpg">
                                <source src="video/ficus.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/ficus.jpg">
                                <source src="video/ficus.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  car -->
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/chair.jpg">
                                <source src="video/chair.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/chair.jpg">
                                <source src="video/chair.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  palace -->
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/drums.jpg">
                                <source src="video/drums.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/drums.jpg">
                                <source src="video/drums.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  fern -->
                    
                    <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/Family.jpg">
                                <source src="video/Family.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/Family.jpg">
                                <source src="video/Family.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>
                  </div><!--  fern -->

                  <div class="w-slide">
                      <div class="div-block-9">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/lego.jpg">
                                  <source src="video/lego.mp4" type="video/mp4">
                                  Your browser does not support the video tag.
                              </video>
                          </div>
                          <div class="video_class mobile w-embed">
                              <video  width=100% height=100% muted controls loop preload="metadata" poster="video/poster/lego.jpg">
                                  <source src="video/lego.mp4" type="video/mp4">
                                  Your browser does not support the video tag.
                              </video>
                          </div>
                      </div>


                      <div class="div-block-9 last_block">
                          <div class="video_class w-embed">
                              <video  width=100% height=100% autoplay muted controls loop preload="metadata" poster="video/poster/mic.jpg">
                                  <source src="video/mic.mp4" type="video/mp4">
                                  Your browser does not support the video tag.
                              </video>
                          </div>
                      <div class="video_class mobile w-embed">
                          <video width=100% height=100% muted controls loop preload="metadata" poster="video/poster/mic.jpg">
                              <source src="video/mic.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                          </video>
                      </div>
                  </div>
              </div>
            </div>

            <div class="w-slider-arrow-left"><div class="w-icon-slider-left"></div></div>
                    <div class="w-slider-arrow-right"><div class="w-icon-slider-right"></div></div>
                    <div class="nerf_slide_nav w-slider-nav w-slider-nav-invert w-round"></div></div>
            </div>
        <!-- </div> -->

        <p class="paragraph-3 nerf_text">
        Our method achieves high reconstruction
        quality, significantly outperforming NeRF, Plenoxels, and
        DVGO on both datasets, while being significantly more compact
        than Plenoxels and DVGO. We also outperform Instant-NGP and
        are on par with TensoRF regarding reconstruction quality, while
        being highly compact with only 5.1M parameters, less than onethird
        of TensoRF-VM and one-half of Instant-NGP. Our DiF-Grid
        also optimizes faster than TensoRF, at slightly over 10 minutes, in addition to our superior compactness. Additionally, unlike Plenoxels
        and Instant-NGP which rely on their own CUDA framework for
        fast reconstruction, our implementation uses the standard PyTorch
        framework, making it easily extendable to other tasks.
        </p>

        <hr>
        <h2 class="grey-heading_nerf">
            Inpainting
        </h2>
        <p class="paragraph-3 nerf_text">
            <b class="SIGGRAPH-color">Input:</b> Masked image pixels<br>
            <b class="SIGGRAPH-color">Evaluation:</b> Visualization effect only since there's no gt in inpainting task;
        </p>
        <div class="columns-5 w-row">
                <img src="img/inpainting.png" style="width:95%; margin-right:0px; margin-top:0px;">
        </div>
        <p class="paragraph-3 nerf_text">
        we show the image regression results on three different
        facial images with various masks and compare them to baseline
        methods that do not use any data priors, including Instant-NGP and
        our DiF-MLP-B without pre-training. As expected, Instant-NGP can
        accurately approximate the training pixels but results in random
        noise in the untrained mask regions. Interestingly, even without
        pre-training and priors from other images, our DiF-MLP-B is able to
        capture structural information to some extent within the same image
        being optimized; as shown in the eye region, the model can learn
        the pupil shape from the right eye and regress the left eye (masked
        during training) by reusing the learned structures in the shared
        basis functions. As shown above, our DiF-MLP-B with
        pre-trained prior clearly achieves the best reconstruction quality
        with better structures and boundary smoothness compared to the
        baselines, demonstrating that our factorized DiF model allows for
        learning and transferring useful prior information from the training
        set.
        </p>

        <hr>
        <h2 class="grey-heading_nerf">
            Few-Shot NeRF
        </h2>
        <p class="paragraph-3 nerf_text">
            <b class="SIGGRAPH-color">Input:</b> 3 or 5 neighboring views, the generalization models we are trained on 100 Google Scanned Object scenes [Downs et al. 2022]<br>
            <b class="SIGGRAPH-color">Evaluation:</b> PSNR/SSIM on novel views; Training time;
        </p>
        <div class="columns-5 w-row">
                <img src="img/few-shot.jpg" style="width:95%; margin-right:0px; margin-top:0px;">
        </div>
        <p class="paragraph-3 nerf_text">
        our pre-trained DiF representation with MLP basis provides strong regularization
        for few-shot reconstruction, resulting in fewer artifacts
        and better reconstruction quality than the single-scene optimization
        methods without data priors and previous few-shot reconstruction
        methods that also use pre-trained networks. In particular, without
        any data priors, single-scene optimization methods (Instant-NGP
        and ours w/o prior) lead to a lot of outliers due to overfitting to
        the few-shot input images. Previous methods like MVSNeRF and
        PixelNeRF achieve plausible reconstructions due to their learned
        feed-forward prediction which avoids per-scene optimization. However,
        they suffer from blurry artifacts. Additionally, the strategy
        taken by PixelNeRF and MVSNeRF assumes a narrow baseline and
        learns correspondences across views for generalization via feature
        averaging or cost volume modeling which does not work as effectively
        in a wide baseline setup. On the other hand, by pre-training
        shared basis fields on multiple signals, our DiF model can learn
        useful data priors, enabling the reconstruction of novel signals from
        sparse observations via optimization.
        </p>
        <hr>

        </br></br></br>
        <s2> Acknowledgements </s2>
        <hr>
        <p class="paragraph-3 nerf_text">
            We would like to thank Bozidar Antic, Zehao Yu, Hansheng Chen, Shaofei Wang for helpful discussion and suggestions. This work was supported by the SNF grant 200021, 204840.
        </p>


        </br></br>
        <s2>Bibtex</s2>
        <hr>
        <p class="paragraph-3 nerf_text">
            This project page includes two papers: <br>
            <ul style="text-align: left; margin-left: 30px">
                <li>Dictionary Fields: Learning a Neural Basis Decomposition
                <li>Factor Fields: A Unified Framework for Neural Fields and Beyond
            </ul>
        </p>
        <p class="paragraph-3 nerf_text">
            Please cite if you find they are helpful:
        </p>
        <div class="bibtexsection">
            @article{Chen2023factor,
              title={Factor Fields: A Unified Framework for Neural Fields and Beyond},
              author={Chen, Anpei and Xu, Zexiang and Wei, Xinyue and 
              Tang, Siyu and Su, Hao and Geiger, Andreas},
              journal={arXiv preprint arXiv:2302.01226},
              year={2023}
            }

            @article{Chen2023SIGGRAPH, 
             title={{Dictionary Fields: Learning a Neural Basis Decomposition}}, 
             author={Anpei, Chen and Zexiang, Xu and Xinyue, Wei and 
             Siyu, Tang and Hao, Su and Andreas, Geiger}, 
             booktitle={International Conference on Computer Graphics and 
             Interactive Techniques (SIGGRAPH)}, 
             year={2023}}
        </div>
    </div>
    <hr>

    <footer>
        <p>This website is partially borrowed from NeRF.
            Send feedback and questions to <a href="https://apchenstu.github.io/">Anpei Chen</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

<script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
<script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd6c33218.js" type="text/javascript"></script>

<!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->

</body>
</html>
